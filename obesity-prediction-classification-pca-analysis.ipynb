{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10465193,"sourceType":"datasetVersion","datasetId":6479256}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Obesity Dataset Classification and PCA Analysis\nIn this project, we will perform classification on an obesity dataset using three different classification algorithms. We will also apply PCA (Principal Component Analysis) to reduce the dimensionality of the data and visualize the results.\n\n---\n\n# Import Libraries\nWe will start by importing the necessary libraries.\n","metadata":{"jupyter":{"source_hidden":true}}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import classification_report\nimport numpy as np\nimport matplotlib.pyplot as plt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T18:13:53.166381Z","iopub.execute_input":"2025-01-25T18:13:53.166791Z","iopub.status.idle":"2025-01-25T18:13:53.171988Z","shell.execute_reply.started":"2025-01-25T18:13:53.166758Z","shell.execute_reply":"2025-01-25T18:13:53.170707Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load and Preprocess the Data\nNext, we will load the dataset and perform preprocessing. We will encode the target variable and convert categorical variables into numerical values using one-hot encoding.\n","metadata":{}},{"cell_type":"code","source":"# Load the dataset\ndata = pd.read_csv(\"/kaggle/input/obesity-prediction/Obesity prediction.csv\")\n\n# Encode the target column (Obesity) into numerical values\nlabel_encoder = LabelEncoder()\ndata[\"Obesity_encoded\"] = label_encoder.fit_transform(data[\"Obesity\"])\n\n# Convert categorical variables into numerical variables\ncategorical_columns = [\"Gender\", \"family_history\", \"FAVC\", \"CAEC\", \"SMOKE\", \"SCC\", \"CALC\", \"MTRANS\"]\ndata = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n\n# Split data into features (X) and target (y)\nX = data.drop(columns=[\"Obesity\", \"Obesity_encoded\"])\ny = data[\"Obesity_encoded\"]\n\n# Split into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Display the shapes of training and test sets\nX_train.shape, X_test.shape\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T18:14:18.909347Z","iopub.execute_input":"2025-01-25T18:14:18.909929Z","iopub.status.idle":"2025-01-25T18:14:18.963408Z","shell.execute_reply.started":"2025-01-25T18:14:18.909891Z","shell.execute_reply":"2025-01-25T18:14:18.962101Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Scale the Features\nWe will standardize the features using `StandardScaler` to ensure that all features have a mean of 0 and a standard deviation of 1.\n","metadata":{}},{"cell_type":"code","source":"# Scale the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T18:14:39.029727Z","iopub.execute_input":"2025-01-25T18:14:39.030219Z","iopub.status.idle":"2025-01-25T18:14:39.043734Z","shell.execute_reply.started":"2025-01-25T18:14:39.030192Z","shell.execute_reply":"2025-01-25T18:14:39.042900Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Logistic Regression Classifier\nWe will train a Logistic Regression model and evaluate its performance using the classification report.\n","metadata":{}},{"cell_type":"code","source":"# Train Logistic Regression model\nlogistic_model = LogisticRegression(max_iter=1000, random_state=42)\nlogistic_model.fit(X_train_scaled, y_train)\n\n# Predict and evaluate\ny_pred_logistic = logistic_model.predict(X_test_scaled)\nprint(\"Logistic Regression Classification Report (scaled data):\")\nprint(classification_report(y_test, y_pred_logistic, target_names=label_encoder.classes_))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T18:15:02.588448Z","iopub.execute_input":"2025-01-25T18:15:02.588807Z","iopub.status.idle":"2025-01-25T18:15:02.696576Z","shell.execute_reply.started":"2025-01-25T18:15:02.588782Z","shell.execute_reply":"2025-01-25T18:15:02.695624Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Random Forest Classifier\nNow, let's train a Random Forest model and evaluate its performance.\n","metadata":{}},{"cell_type":"code","source":"# Train Random Forest model\nrf_model = RandomForestClassifier(random_state=42)\nrf_model.fit(X_train_scaled, y_train)\n\n# Predict and evaluate\ny_pred_rf = rf_model.predict(X_test_scaled)\nprint(\"Random Forest Classification Report:\")\nprint(classification_report(y_test, y_pred_rf, target_names=label_encoder.classes_))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T18:15:22.410704Z","iopub.execute_input":"2025-01-25T18:15:22.411149Z","iopub.status.idle":"2025-01-25T18:15:22.772038Z","shell.execute_reply.started":"2025-01-25T18:15:22.411118Z","shell.execute_reply":"2025-01-25T18:15:22.770942Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Support Vector Machine (SVM) Classifier\nNext, we will train a Support Vector Machine (SVM) model and evaluate its performance.\n","metadata":{}},{"cell_type":"code","source":"# Train Support Vector Machine (SVM) model\nsvm_model = SVC(random_state=42)\nsvm_model.fit(X_train_scaled, y_train)\n\n# Predict and evaluate\ny_pred_svm = svm_model.predict(X_test_scaled)\nprint(\"Support Vector Machine (SVM) Classification Report:\")\nprint(classification_report(y_test, y_pred_svm, target_names=label_encoder.classes_))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T18:15:40.756392Z","iopub.execute_input":"2025-01-25T18:15:40.756825Z","iopub.status.idle":"2025-01-25T18:15:40.900233Z","shell.execute_reply.started":"2025-01-25T18:15:40.756791Z","shell.execute_reply":"2025-01-25T18:15:40.898967Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Apply PCA (Principal Component Analysis)\nNow, let's apply PCA to reduce the dimensionality of the data to 2 components. We will then train a Logistic Regression model using the reduced data.\n","metadata":{}},{"cell_type":"code","source":"# Apply PCA for dimensionality reduction\npca = PCA(n_components=2)  # Reduce to 2 components\nX_train_pca = pca.fit_transform(X_train_scaled)\nX_test_pca = pca.transform(X_test_scaled)\n\n# Train Logistic Regression model on PCA-transformed data\nlogistic_model_pca = LogisticRegression(max_iter=10000, random_state=42)\nlogistic_model_pca.fit(X_train_pca, y_train)\n\n# Predict and evaluate\ny_pred_pca = logistic_model_pca.predict(X_test_pca)\nprint(\"Logistic Regression (PCA) Classification Report:\")\nprint(classification_report(y_test, y_pred_pca, target_names=label_encoder.classes_))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T18:15:56.984186Z","iopub.execute_input":"2025-01-25T18:15:56.984591Z","iopub.status.idle":"2025-01-25T18:15:57.033249Z","shell.execute_reply.started":"2025-01-25T18:15:56.984523Z","shell.execute_reply":"2025-01-25T18:15:57.032107Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualize PCA Components\nLet's visualize the 2 PCA components to understand the distribution of different classes in the reduced feature space.\n","metadata":{}},{"cell_type":"code","source":"# Visualize PCA components\nplt.figure(figsize=(8, 6))\nfor label in np.unique(y_train):\n    plt.scatter(X_train_pca[y_train == label, 0], X_train_pca[y_train == label, 1], label=label_encoder.inverse_transform([label])[0])\nplt.title(\"PCA Components Scatter Plot\")\nplt.xlabel(\"Principal Component 1\")\nplt.ylabel(\"Principal Component 2\")\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T18:16:13.774900Z","iopub.execute_input":"2025-01-25T18:16:13.775240Z","iopub.status.idle":"2025-01-25T18:16:14.242161Z","shell.execute_reply.started":"2025-01-25T18:16:13.775215Z","shell.execute_reply":"2025-01-25T18:16:14.241045Z"}},"outputs":[],"execution_count":null}]}